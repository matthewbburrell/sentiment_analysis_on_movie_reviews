{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "useful-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import script.functions as func\n",
    "import pickle\n",
    "import autoreload \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from hpsklearn import HyperoptEstimator, multinomial_nb, tfidf\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from hyperopt import hp, Trials, tpe, fmin, space_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forbidden-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data \n",
    "train = pd.read_csv('../data/train.tsv', delimiter='\\t')\n",
    "test = pd.read_csv('../data/test.tsv', delimiter='\\t')\n",
    "\n",
    "#Processs data (Please see function.py for description)\n",
    "train = func.text_processing(train)\n",
    "test = func.text_processing(test)\n",
    "\n",
    "#Save clean data \n",
    "#train.to_csv('../data/clean_train.csv')\n",
    "#test.to_csv('../data/clean_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-order",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "middle-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['Phrase']\n",
    "y = train['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "mature-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/trial, best loss: 0.4835557673975215]\n",
      "100%|██████████| 2/2 [00:02<00:00,  2.63s/trial, best loss: 0.45527486495074676]\n",
      "100%|██████████| 3/3 [00:02<00:00,  2.58s/trial, best loss: 0.45527486495074676]\n",
      "100%|██████████| 4/4 [00:03<00:00,  3.15s/trial, best loss: 0.45527486495074676]\n",
      "100%|██████████| 5/5 [00:00<00:00,  1.06trial/s, best loss: 0.45527486495074676]\n",
      "100%|██████████| 6/6 [00:02<00:00,  2.57s/trial, best loss: 0.45527486495074676]\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.95s/trial, best loss: 0.45527486495074676]\n",
      "100%|██████████| 8/8 [00:01<00:00,  1.93s/trial, best loss: 0.45527486495074676]\n",
      "100%|██████████| 9/9 [00:02<00:00,  2.73s/trial, best loss: 0.45527486495074676]\n",
      "100%|██████████| 10/10 [00:01<00:00,  2.00s/trial, best loss: 0.45527486495074676]\n"
     ]
    }
   ],
   "source": [
    "#Optimizing using hyper-opt sklearn\n",
    "estimator = HyperoptEstimator(classifier= multinomial_nb('nb'),\n",
    "                              preprocessing = [tfidf('tf')], \n",
    "                             algo=tpe.suggest)\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "unable-crest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.7751561084894418\n",
      "Test Score: 0.5530505243088656\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Score: {estimator.score(X_train, y_train)}')\n",
    "print(f'Test Score: {estimator.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "documented-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:42<00:00,  4.26s/trial, best loss: 0.44212458726097004]\n"
     ]
    }
   ],
   "source": [
    "#Optimizing using hyper-opt\n",
    "pipe = Pipeline([('tf_vec', TfidfVectorizer()),\n",
    "                ('nb', MultinomialNB())])\n",
    "\n",
    "space = {}\n",
    "space['tf_vec__ngram_range'] = hp.choice('tf_vec__ngram_range', [(1,1), (1,2), (1,3)])\n",
    "space['tf_vec__stop_words'] = hp.choice('tf_vec__stop_words', [None, 'english'])\n",
    "space['tf_vec__min_df'] = hp.randint('tf_vec__min_df', 3)\n",
    "space['tf_vec__max_df'] = hp.uniform('tf_vec__max_df', 0.7, 1.0)\n",
    "space['nb__alpha'] = hp.loguniform('nb__alpha', 0,1)\n",
    "\n",
    "def objective(params):\n",
    "    pipe.set_params(**params)\n",
    "    score = cross_val_score(pipe, X_train, y_train, cv=5)\n",
    "    return 1 - score.mean()\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(objective,\n",
    "            space,\n",
    "            algo = tpe.suggest,\n",
    "           max_evals=10,\n",
    "           trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "heard-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.6374310818755263\n",
      "Test Score: 0.5600095328884652\n"
     ]
    }
   ],
   "source": [
    "best_params = space_eval(space, best)\n",
    "pipe.set_params(**best_params)\n",
    "pipe.fit(X_train, y_train)\n",
    "print(f'Train Score: {pipe.score(X_train, y_train)}')\n",
    "print(f'Test Score: {pipe.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "owned-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle the models\n",
    "pickle.dump(estimator, open( \"../models/nb_1.pkl\", \"wb\" ))\n",
    "pickle.dump(pipe, open( \"../models/nb_2.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-distribution",
   "metadata": {},
   "source": [
    "## Neural Network Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-sector",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
